import { GoogleGenerativeAI, HarmCategory, HarmBlockThreshold } from "@google/generative-ai";

const apiKey = import.meta.env.VITE_GOOGLE_API_KEY;
const genAI = new GoogleGenerativeAI(apiKey);

// ğŸ§¹ [ë„êµ¬] í…ìŠ¤íŠ¸ ì •ê·œí™” (ê³µë°±ë§Œ ì œê±°)
const normalizeText = (text) => {
  return text.replace(/\s+/g, '').toLowerCase(); 
};

// ğŸ›‘ [1ì°¨: ì ˆëŒ€ ì°¨ë‹¨ ë¸”ë™ë¦¬ìŠ¤íŠ¸]
// í…ìŠ¤íŠ¸ëŠ” ì—¬ê¸°ì„œ 100% ì¡í™ë‹ˆë‹¤. (ì„±ê³µ í™•ì¸ë¨)
const CRITICAL_KEYWORDS = [
  'ì‚´ì¸', 'ì‚´í•´', 'ì²­ë¶€', 'ì•”ì‚´', 'ë„ì‚´', 'ë‚œì', 'í† ë§‰', 'ì‹œì²´', 
  'í…ŒëŸ¬', 'í­íƒ„', 'í­ë°œë¬¼', 'ì‚¬ì œì´', 'í™”ì—¼ë³‘', 'ì´ê¸°', 'ì‹¤íƒ„', 'ìˆ˜ë¥˜íƒ„', 'í…ŒëŸ¬ë¦¬ìŠ¤íŠ¸',
  'ì„±í­í–‰', 'ê°•ê°„', 'ìœ¤ê°„', 'ê°•ì œì¶”í–‰', 'ì„±ë…¸ì˜ˆ', 'ìµœìŒì œ', 'ë°œì •ì œ', 'ë¬¼ë½•',
  'ë”¥í˜ì´í¬', 'ì§€ì¸ëŠ¥ìš•', 'ëª°ì¹´', 'ë„ì´¬', 'ë¦¬ë²¤ì§€í¬ë¥´ë…¸', 'ì´ˆëŒ€ë‚¨',
  'ì•„ë™í¬ë¥´ë…¸', 'í˜ë„', 'ë¡œë¦¬', 'ì‡¼íƒ€', 'ê·¼ì¹œ', 'ìˆ˜ê°„', 'ëŠ¥ìš•',
  'ì„±ë§¤ë§¤', 'ì¡°ê±´ë§Œë‚¨', 'ì›ì¡°êµì œ', 'ì¡°ê±´ë…€', 'ì¡°ê±´ë‚¨', 'ì¶œì¥ìƒµ', 'ì• ì¸ëŒ€í–‰', 
  'í‚¤ìŠ¤ë°©', 'ì•ˆë§ˆë°©', 'ì˜¤í”¼', 'ë¦½ì¹´í˜', 'ì„±ë§¤ìˆ˜', 'ë§¤ì¶˜',
  'ë§ˆì•½', 'ëŒ€ë§ˆ', 'ëŒ€ë§ˆì´ˆ', 'ë–¨', 'ê³ ê¸°', 'ì•„ì´ìŠ¤', 'ì‘ëŒ€ê¸°', 
  'í•„ë¡œí°', 'íˆë¡œë½•', 'ë©”ìŠ¤ì•”í˜íƒ€ë¯¼', 'íœíƒ€ë‹', 'í—¤ë¡œì¸', 'ì½”ì¹´ì¸', 'ì—‘ìŠ¤í„°ì‹œ', 'LSD', 
  'ì¡¸í”¼ë€', 'í”„ë¡œí¬í´', 'ì¼€íƒ€ë¯¼', 'ì‚¬ì¹´ë¦°', 'í•´í”¼ë²Œë£¬',
  'ìì‚´', 'ìí•´', 'ë™ë°˜ìì‚´', 'ì•ˆë½ì‚¬', 'ì†ëª©ê¸‹ê¸°', 'ëª©ë§¤ë‹¬ê¸°', 'íˆ¬ì‹ '
];

export const analyzeContent = async (text, imageBase64 = null, context = 'post') => {
  const cleanText = normalizeText(text || "");
  console.log(`ğŸ›¡ï¸ [AI ê²€ì‚¬ ì‹œì‘] ì…ë ¥ê°’: "${text}"`);

  // =================================================
  // 1ï¸âƒ£ [1ì°¨ ì—¬ê³¼ê¸°] ë¸”ë™ë¦¬ìŠ¤íŠ¸ (í…ìŠ¤íŠ¸ ì¦‰ì‹œ ì°¨ë‹¨)
  // =================================================
  const foundDanger = CRITICAL_KEYWORDS.find(k => cleanText.includes(k));
  if (foundDanger) {
    console.warn(`ğŸš¨ [1ì°¨ ì°¨ë‹¨] ê¸ˆì§€ì–´ ê²€ì¶œ: ${foundDanger}`);
    return { isSafe: false, reason: `ë¶€ì ì ˆí•œ ë‹¨ì–´("${foundDanger}")ê°€ í¬í•¨ë˜ì–´ ìˆìŠµë‹ˆë‹¤.` };
  }

  // =================================================
  // 2ï¸âƒ£ [AI ëª¨ë¸ ë¶„ì„] (Gemini 1.5 Flash)
  // =================================================
  try {
    // ğŸ”¥ [ìˆ˜ì •] ëª¨ë¸ ì´ë¦„ì„ ê°€ì¥ ì‹¬í”Œí•œ 'gemini-1.5-flash'ë¡œ ë³€ê²½
    // ë§Œì•½ ì´ë˜ë„ 404ê°€ ëœ¨ë©´, ê·¸ê±´ ì§„ì§œ 'í‚¤' ë¬¸ì œë¼ ì½”ë“œë¡œëŠ” í•´ê²° ë¶ˆê°€í•¨.
    const model = genAI.getGenerativeModel({ model: "gemini-1.5-flash" });

    const safetySettings = [
      { category: HarmCategory.HARM_CATEGORY_HARASSMENT, threshold: HarmBlockThreshold.BLOCK_NONE },
      { category: HarmCategory.HARM_CATEGORY_HATE_SPEECH, threshold: HarmBlockThreshold.BLOCK_NONE },
      { category: HarmCategory.HARM_CATEGORY_SEXUALLY_EXPLICIT, threshold: HarmBlockThreshold.BLOCK_NONE },
      { category: HarmCategory.HARM_CATEGORY_DANGEROUS_CONTENT, threshold: HarmBlockThreshold.BLOCK_NONE },
    ];

    let prompt = `
      You are a strict safety officer.
      Analyze the text and image provided.
      
      [Rules]
      1. BLOCK(false): Nudity, Porn, Sexual content, Real Violence, Drugs.
      2. ALLOW(true): Daily life, Food, Pets (Cats/Dogs), Games.
      
      Input Text: "${text}"
      Context: ${context}
      
      Respond ONLY with this JSON format (No Markdown):
      { "isSafe": boolean, "reason": "Reason in Korean" }
    `;

    // í…ìŠ¤íŠ¸ í¬ì¥
    let requestParts = [{ text: prompt }];

    if (imageBase64) {
      const base64Data = imageBase64.split(',')[1];
      requestParts.push({ inlineData: { data: base64Data, mimeType: "image/jpeg" } });
    }

    console.log("ğŸ¤– AI ëª¨ë¸ í˜¸ì¶œ ì¤‘...");

    const result = await model.generateContent({
      contents: [{ role: "user", parts: requestParts }],
      safetySettings: safetySettings,
    });

    const response = await result.response;
    const textResponse = response.text();
    console.log("ğŸ¤– [AI ì‘ë‹µ]:", textResponse);

    // 3ï¸âƒ£ [2ì°¨ ì—¬ê³¼ê¸°] êµ¬ê¸€ ì•ˆì „ ì„¼ì„œ
    if (response.candidates && response.candidates[0].safetyRatings) {
      const ratings = response.candidates[0].safetyRatings;
      const targetCategories = [
        HarmCategory.HARM_CATEGORY_SEXUALLY_EXPLICIT,
        HarmCategory.HARM_CATEGORY_DANGEROUS_CONTENT
      ];

      for (const rating of ratings) {
        if (targetCategories.includes(rating.category)) {
          // MEDIUM ì´ìƒì´ë©´ ë¬´ì¡°ê±´ ì°¨ë‹¨
          if (rating.probability === "HIGH" || rating.probability === "MEDIUM") {
            console.warn(`ğŸš¨ [2ì°¨ ì°¨ë‹¨] ì„¼ì„œ ê°ì§€: ${rating.category} (${rating.probability})`);
            return { isSafe: false, reason: "ì´ë¯¸ì§€ ë˜ëŠ” í…ìŠ¤íŠ¸ì—ì„œ ìœ í•´í•œ ìš”ì†Œê°€ ê°ì§€ë˜ì—ˆìŠµë‹ˆë‹¤." };
          }
        }
      }
    }

    // 4ï¸âƒ£ [3ì°¨ ì—¬ê³¼ê¸°] JSON íŒŒì‹±
    const startIndex = textResponse.indexOf('{');
    const endIndex = textResponse.lastIndexOf('}');
    
    if (startIndex === -1 || endIndex === -1) {
      throw new Error("JSON í˜•ì‹ì„ ì°¾ì„ ìˆ˜ ì—†ìŒ");
    }

    const jsonString = textResponse.substring(startIndex, endIndex + 1);
    return JSON.parse(jsonString);

  } catch (error) {
    console.error("ğŸš¨ AI ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜:", error);
    
    // ğŸ”¥ [ë³´ì•ˆ ìµœìš°ì„ ] AIê°€ ê³ ì¥ ë‚˜ë©´?
    // "ì–´ì©” ìˆ˜ ì—†ë‹¤. ì´ë¯¸ì§€ê°€ ìˆìœ¼ë©´ ìœ„í—˜í•˜ë‹ˆ ë¬´ì¡°ê±´ ë§‰ëŠ”ë‹¤."
    if (imageBase64) {
        return { isSafe: false, reason: "AI ì—°ê²° ì‹¤íŒ¨: ì´ë¯¸ì§€ë¥¼ ê²€ì‚¬í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. (ì ì‹œ í›„ ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”)" };
    }
    
    // í…ìŠ¤íŠ¸ë§Œ ìˆìœ¼ë©´ 1ì°¨ í•„í„° í†µê³¼í–ˆìœ¼ë‹ˆ ë´ì¤Œ.
    return { isSafe: true, reason: "AI ì§€ì—° (í…ìŠ¤íŠ¸ë§Œ ì„ì‹œ ìŠ¹ì¸)" };
  }
};